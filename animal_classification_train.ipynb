{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26952,"status":"ok","timestamp":1719587739316,"user":{"displayName":"QUÂN NGUYỄN MINH","userId":"16744287039057699685"},"user_tz":-420},"id":"SYEJsdCpBhpt","outputId":"9a72b6d9-9d07-4894-f3d5-8099269aef38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/.shortcut-targets-by-id/1PX4wlgoBojg5BTTQ3yOEDoz8vk2IF1ju/animal-code\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","path = '/content/gdrive/My Drive/MyCode/animal-code'\n","%cd {path}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kbbji4Rm_pl7"},"outputs":[],"source":["import os\n","import shutil\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from torch.optim.lr_scheduler import MultiStepLR\n","from torchvision.transforms import Compose, ToTensor, Resize\n","from torch.optim import SGD, Adagrad, Adam\n","from torch.utils.tensorboard import SummaryWriter\n","import pickle\n","import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","from torchsummary import summary\n","import numpy as np\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","import matplotlib.pyplot as plt\n","import argparse\n","from tqdm.autonotebook import tqdm\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PtEYYWnK4WYj"},"outputs":[],"source":["class AnimalDataset(Dataset):\n","    def __init__(self, root = \"animals\", train=True, transform = None):\n","        self.categories = [\"butterfly\", \"cat\", \"chicken\", \"cow\", \"dog\", \"elephant\", \"horse\", \"sheep\", \"spider\", \"squirrel\"]\n","\n","        if train:\n","            data_path = os.path.join(root, \"train\")\n","        else:\n","            data_path = os.path.join(root, \"test\")\n","\n","        self.image_paths = []\n","        self.labels = []\n","\n","        for category in self.categories:\n","            category_path = os.path.join(data_path, category)\n","            for image_name in os.listdir(category_path):\n","                image_path = os.path.join(category_path, image_name)\n","                self.image_paths.append(image_path)\n","                self.labels.append(self.categories.index(category))\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, item):\n","        image = cv2.imread(self.image_paths[item])\n","        if self.transform:\n","            image = self.transform(image)\n","        label = self.labels[item]\n","\n","        return image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aotiNQ5gGE7P"},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self, num_classes = 10):\n","        super().__init__()\n","\n","        self.conv1 = self.make_block(in_channels = 3, out_channels = 16)\n","        self.conv2 = self.make_block(in_channels = 16, out_channels = 32)\n","        self.conv3 = self.make_block(in_channels = 32, out_channels = 64)\n","        self.conv4 = self.make_block(in_channels = 64, out_channels = 64)\n","        self.conv5 = self.make_block(in_channels = 64, out_channels = 64)\n","\n","        self.fc1 = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(in_features=3136, out_features=1024),\n","            nn.LeakyReLU()\n","        )\n","\n","        self.fc2 = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(in_features=1024, out_features=512),\n","            nn.LeakyReLU()\n","        )\n","\n","        self.fc3 = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(in_features=512, out_features=num_classes),\n","            nn.LeakyReLU()\n","        )\n","\n","    def make_block(self, in_channels, out_channels):\n","        return nn.Sequential(\n","            nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = 3, padding = 1),\n","            nn.BatchNorm2d(num_features=out_channels),\n","            nn.LeakyReLU(),\n","            nn.Conv2d(in_channels = out_channels, out_channels = out_channels, kernel_size = 3, padding = 1),\n","            nn.BatchNorm2d(num_features=out_channels),\n","            nn.LeakyReLU(),\n","            nn.MaxPool2d(kernel_size=2) # Mặc định strike = kernel_size\n","          )\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","        x = x.view(x.shape[0], -1) #giữ lại chiều đầu tiên, gộp các chiều còn lại\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AvJlQZQGjfyQ"},"outputs":[],"source":["def plot_confusion_matrix(writer, cm, class_names, epoch):\n","    \"\"\"\n","    Returns a matplotlib figure containing the plotted confusion matrix.\n","\n","    Args:\n","       cm (array, shape = [n, n]): a confusion matrix of integer classes\n","       class_names (array, shape = [n]): String names of the integer classes\n","    \"\"\"\n","\n","    figure = plt.figure(figsize=(20, 20))\n","    # color map: https://matplotlib.org/stable/gallery/color/colormap_reference.html\n","    plt.imshow(cm, interpolation='nearest', cmap=\"cool\")\n","    plt.title(\"Confusion matrix\")\n","    plt.colorbar()\n","    tick_marks = np.arange(len(class_names))\n","    plt.xticks(tick_marks, class_names, rotation=45)\n","    plt.yticks(tick_marks, class_names)\n","\n","    # Normalize the confusion matrix.\n","    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n","\n","    # Use white text if squares are dark; otherwise black.\n","    threshold = cm.max() / 2.\n","\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            color = \"white\" if cm[i, j] > threshold else \"black\"\n","            plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    writer.add_figure('confusion_matrix', figure, epoch)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJMeT5KItI9k"},"outputs":[],"source":["def get_args():\n","    parser = argparse.ArgumentParser(description='Animal classifier')\n","    parser.add_argument('-p', '--data_path', type=str, default=\"./animals\")\n","    parser.add_argument('-b', '--batch_size', type=int, default=16)\n","    parser.add_argument('-e', '--epochs', type=int, default=100)\n","    parser.add_argument('-l', '--lr', type=float, default=1e-3)  # SGD: lr = 1e-2. Adam: lr = 1e-3\n","    parser.add_argument('-s', '--image_size', type=int, default=224)\n","    parser.add_argument('-c', '--checkpoint_path', type=str, default=None)\n","    parser.add_argument('-t', '--tensorboard_path', type=str, default=\"tensorboard\")\n","    parser.add_argument('-r', '--trained_path', type=str, default=\"trained_models\")\n","    args, unknown = parser.parse_known_args()\n","    return args"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eBUjDo2VMvmy"},"outputs":[],"source":["def train(args):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    transform = Compose([\n","        ToTensor(),\n","        Resize((args.image_size, args.image_size))\n","    ])\n","    train_set = AnimalDataset(root=args.data_path, train=True, transform=transform)\n","    valid_set = AnimalDataset(root=args.data_path, train=False, transform=transform)\n","\n","    training_params = {\n","        \"batch_size\": args.batch_size,\n","        \"shuffle\": True,\n","        \"drop_last\": True,\n","        \"num_workers\": 6\n","    }\n","\n","    valid_params = {\n","        \"batch_size\": args.batch_size,\n","        \"shuffle\": False,\n","        \"drop_last\": False,\n","        \"num_workers\": 6\n","    }\n","    train_dataloader = DataLoader(train_set, **training_params)\n","    valid_dataloader = DataLoader(valid_set, **valid_params)\n","\n","    model = CNN(num_classes=len(train_set.categories)).to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = Adam(model.parameters(), lr=args.lr)\n","    scheduler = MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.1)\n","\n","    if args.checkpoint_path and os.path.isfile(args.checkpoint_path):\n","        checkpoint = torch.load(args.checkpoint_path)\n","        model.load_state_dict(checkpoint[\"model\"])\n","        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","        start_epoch = checkpoint[\"epoch\"] + 1\n","        best_acc = checkpoint[\"best_acc\"]\n","    else:\n","        start_epoch = 0\n","        best_acc = 0\n","\n","    if os.path.isdir(args.tensorboard_path):\n","        shutil.rmtree(args.tensorboard_path)\n","    os.mkdir(args.tensorboard_path)\n","\n","    if not os.path.isdir(args.trained_path):\n","        os.mkdir(args.trained_path)\n","    writer = SummaryWriter(args.tensorboard_path)\n","    num_iters = len(train_dataloader)\n","\n","    for epoch in range(start_epoch, args.epochs):\n","        # TRAIN\n","        model.train()\n","        losses = []\n","        progress_bar = tqdm(train_dataloader, colour=\"yellow\")\n","        for iter, (images, labels) in enumerate(progress_bar):\n","            # Move tensor to configured device:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            # Forward pass\n","            predictions = model(images)\n","            loss = criterion(predictions, labels)\n","\n","            # Backward and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            loss_value = loss.item()\n","            progress_bar.set_description(\"Epoch {}/{}. Loss value: {:.4f}\".format(epoch + 1, args.epochs, loss_value))\n","            losses.append(loss_value)\n","            writer.add_scalar(\"Train/Loss\", np.mean(losses), epoch*num_iters+iter)\n","\n","        # VALIDATE\n","        model.eval()\n","        losses = []\n","        all_predictions = []\n","        all_gts = []\n","        with torch.no_grad():  # with torch.inference_mode():  # pytorch 1.9\n","            for iter, (images, labels) in enumerate(valid_dataloader):\n","                # Move tensor to configured device:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","\n","                # Forward pass\n","                predictions = model(images)\n","                max_idx = torch.argmax(predictions, 1)\n","\n","                # _, max_idx = torch.max(predictions, 1)\n","                loss = criterion(predictions, labels)\n","                losses.append(loss.item())\n","                all_gts.extend(labels.tolist())\n","                all_predictions.extend(max_idx.tolist())\n","\n","        writer.add_scalar(\"Val/Loss\", np.mean(losses), epoch)\n","        acc = accuracy_score(all_gts, all_predictions)\n","        writer.add_scalar(\"Val/Accuracy\", acc, epoch)\n","        conf_matrix = confusion_matrix(all_gts, all_predictions)\n","        plot_confusion_matrix(writer, conf_matrix, [i for i in range(len(train_set.categories))], epoch)\n","\n","        checkpoint = {\n","            \"model\": model.state_dict(),\n","            \"optimizer\": optimizer.state_dict(),\n","            \"epoch\": epoch,\n","            \"best_acc\": best_acc,\n","            \"batch_size\": args.batch_size\n","        }\n","\n","        torch.save(checkpoint, os.path.join(args.trained_path, \"last.pt\"))\n","        if acc > best_acc:\n","            torch.save(checkpoint, os.path.join(args.trained_path, \"best.pt\"))\n","            best_acc = acc\n","        scheduler.step()\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Bb4DmhsCuDUf","executionInfo":{"status":"ok","timestamp":1719737699626,"user_tz":-420,"elapsed":6,"user":{"displayName":"Minh Quân Nguyễn","userId":"06494375991177715676"}}},"outputs":[],"source":["if __name__ == '__main__':\n","    args = get_args()\n","    train(args)"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}